{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5lSOlR8whwvNG/Yr8xZSl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/f-ssemwanga/MachineLearning_DeepLearning/blob/main/005NeuralNetworkRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Introduction to regression with Neural Networks in Tensor Flow\n",
        "\n",
        "* Regression problem is the predicting of a numberical variable based on some other combination  of variables   \n"
      ],
      "metadata": {
        "id": "T1eXOjyBLF6v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "061DF9xtKru_",
        "outputId": "1717fab8-5b01-4568-f711-fea5e349d45f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow Version: 2.11.0\n"
          ]
        }
      ],
      "source": [
        "#Get some data\n",
        "import tensorflow as tf\n",
        "print(f'Tensorflow Version: {tf.__version__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Creating data to view and fit***"
      ],
      "metadata": {
        "id": "BiwRogXPb2at"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#create features / predictions\n",
        "x = np.array([-7.0, -4.0, -1.0,2.0, 5.0, 8.0, 11.0, 14.0 ])\n",
        "#create labels\n",
        "y=np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "#visualise it\n",
        "plt.scatter(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "9XyrRndQcA3w",
        "outputId": "3f8cf308-4497-4656-9b69-af4a17b8e278"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fc2fbb6e3a0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from the above\n",
        "y == x+10 # this is the function / relationship we want our Neural Network to learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMyzaYyrdRPK",
        "outputId": "fb4d6a79-1579-4a7f-9357-ef9b8df93b82"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##input and output shapes\n",
        "* if we are to build a model between x and y what might be the shapes of the input and output?"
      ],
      "metadata": {
        "id": "zKHQDc29d7Gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create a demo tensor for the housing price preduction problem\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrsdf-nAeeIg",
        "outputId": "1095e489-de5b-4385-cdcd-640d8da063ed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#input and output shape for the scatter above\n",
        "input_shape = x.shape\n",
        "output_shape =y.shape\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63RQnch7fTSo",
        "outputId": "7635b83c-f69f-4f6d-aaca-f5f7897ad3b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8,), (8,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#use one input i.e. one x value/ feature to predict one y value/ feature\n",
        "x[0], y[0] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQXQhQdnfnQM",
        "outputId": "a8b366c3-cda7-4422-c725-18af3397e6f8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[1],y[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vF8lgZahgDRF",
        "outputId": "5dad6804-983b-4fb2-ff0c-a50d1c90f0ac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-4.0, 6.0)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Turn numpy arrays into tensors\n",
        "x =tf.constant(x)\n",
        "y = tf.constant(y)\n",
        "x,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pFCv57klOPJ",
        "outputId": "7370fba0-dadf-4f98-88ec-137fab176e4b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = x[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape,output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgw3a6Dslc7M",
        "outputId": "6cdcace5-750a-4f9d-fe9e-51e57f6c39f2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "23exjAZwmPOi",
        "outputId": "bc3ff554-faad-4b23-e9b2-187bb773cc7a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fc2f727a220>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Steps in modelling with TensorFlow**\n",
        "\n",
        "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
        "2. **Compile the model** - define the **loss function** (tells the mode how wrong it is), the **optimiser** (tells the model how to improve the patterns it is learning and **Evaluation metrics** (we use these to interpret the performance of a our model)\n",
        "3. **Fitting a mode** - letting the model try to find the patterns between x and y (features and labels)\n",
        "\n",
        "*side note: The choice of 42 as a seed value is somewhat arbitrary, but it has become a convention in the programming community due to its association with the book \"The Hitchhiker's Guide to the Galaxy\" by Douglas Adams, where it is famously referred to as the \"Answer to the Ultimate Question of Life, the Universe, and Everything.\"*\n",
        "\n",
        "* mae - **mean absolute Error** - commonly used loss function for regression problems.  Measures the average absloute difference between the predicted and actual values. **It measures the accuracy of the model's predictions i.e. on average how wrong are the predictions**\n",
        "* A lower mae indicates the model is better at predicting the target variable, normally used in conjunction with the RMSE (root mean square error) to get a better understanding of the model's performance\n",
        "* sgd **stochastic gradient decent** - optimisation algorithm which minimises the loss function during the training process - basically tells the optimiser how to improve\n",
        "\n"
      ],
      "metadata": {
        "id": "IF5ScKgombPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "'''#following creation, compile and fitting from documentation\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense([1]))\n",
        "model.compile(optimizer=\"sgd\", loss='mae')\n",
        "model.fit(x,y,batch_size=32, epochs=5)'''\n",
        "\n",
        "#1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)# because we need 1 input to predict one output in this example\n",
        "])\n",
        "#2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, #loss mae means mean absloute error\n",
        "              optimizer =\"sgd\", #sgd is stochastic gradient decent\n",
        "              metrics=[\"mae\"]) \n"
      ],
      "metadata": {
        "id": "j6APYICDmTIb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check data types before fitting\n",
        "x.dtype, y.dtype\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GMaEn2R3966",
        "outputId": "5082dd9d-9d98-4f8c-a1b7-a564fc1114e7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tf.float64, tf.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#As keras dense layer uses float32 we will change the type before fitting the model\n",
        "x =tf.cast(x,tf.float32)\n",
        "y =tf.cast(y, tf.float32)\n",
        "\n",
        "#now fit the model\n",
        "#3. Fit the model\n",
        "#The code adds an extra dimension to X on the last axis, turning it ndim=1 to ndim=2 (what the model requires).\n",
        "model.fit(tf.expand_dims(x, axis=-1),y,epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN1d9h0c4Mdd",
        "outputId": "d69654e3-cb7d-4e62-9513-fb12c8bc37d6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 12.1982 - mae: 12.1982\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 12.0657 - mae: 12.0657\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 11.9332 - mae: 11.9332\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11.8007 - mae: 11.8007\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 11.6682 - mae: 11.6682\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc2ee7ec670>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the model above to make a prediction\n",
        "#check out x and y\n",
        "x,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq3Ufxcn53hh",
        "outputId": "b34bf19f-a115-4a90-a922-f97fa18f6f6e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#try and make a prediction using the model\n",
        "y_pred = model.predict([17.0])\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEefbFd56MnA",
        "outputId": "5a1ef652-4903-4aa3-8d03-b00a29c52153"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 44ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.017537]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Improving the Neural Network Model's performance\n",
        "We can improve the model by altering the steps taken to create it\n",
        "1. **Creating a Model** \n",
        "  * Add more layers, \n",
        "  * increase number of hidden units (neurons) within each hidden layer\n",
        "  * change the activation function of each layer\n",
        "2. **Compiling a model**\n",
        "  * Change the optimization function\n",
        "  * change the **learning rate (lr)** of the optimization function - the higher the rate the more the optimization algorithm pushes the model to improve\n",
        "3. **Fitting a model**\n",
        "  * fit the model for more epochs (leave it training for longer)\n",
        "  * more data (give the model more examples to learn from)"
      ],
      "metadata": {
        "id": "cHxsJ4Yg_bhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Improving the model by improving the epochs\n",
        "#Create the model\n",
        "model =tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "#compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=\"sgd\",\n",
        "              metrics =['mae'])\n",
        "#Fit the model (this time training for longer)\n",
        "model.fit(tf.expand_dims(x, axis=-1),y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83PQwXMS6guX",
        "outputId": "8140753d-a4f7-42a8-8138-5abf50fa2daa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 8.1635 - mae: 8.1635\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.0310 - mae: 8.0310\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.8985 - mae: 7.8985\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.7660 - mae: 7.7660\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.6335 - mae: 7.6335\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.5010 - mae: 7.5010\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.4550 - mae: 7.4550\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.4494 - mae: 7.4494\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.4438 - mae: 7.4438\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.4381 - mae: 7.4381\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.4325 - mae: 7.4325\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.4269 - mae: 7.4269\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.4213 - mae: 7.4213\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.4156 - mae: 7.4156\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.4100 - mae: 7.4100\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.4044 - mae: 7.4044\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.3988 - mae: 7.3988\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.3931 - mae: 7.3931\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.3875 - mae: 7.3875\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.3819 - mae: 7.3819\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.3762 - mae: 7.3762\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.3706 - mae: 7.3706\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.3650 - mae: 7.3650\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.3594 - mae: 7.3594\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3538 - mae: 7.3538\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.3481 - mae: 7.3481\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3425 - mae: 7.3425\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3369 - mae: 7.3369\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.3313 - mae: 7.3313\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.3256 - mae: 7.3256\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.3200 - mae: 7.3200\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.3144 - mae: 7.3144\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3087 - mae: 7.3087\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.3031 - mae: 7.3031\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2975 - mae: 7.2975\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2919 - mae: 7.2919\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2863 - mae: 7.2863\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2806 - mae: 7.2806\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2750 - mae: 7.2750\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.2694 - mae: 7.2694\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.2638 - mae: 7.2638\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2581 - mae: 7.2581\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.2413 - mae: 7.2413\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1963 - mae: 7.1963\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1738 - mae: 7.1738\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1063 - mae: 7.1063\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9319 - mae: 6.9319\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc2f43b3460>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remind ouselves of the data\n",
        "x,y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrbzL-nJEHhn",
        "outputId": "09a6ff02-a3a2-4d25-84cd-752bf6e5da5c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#See if model prediction has improved\n",
        "model.predict([17.0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzCn3jWcEsBv",
        "outputId": "a8d01a0d-6422-4b62-a2a0-c370c206ec4e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 57ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[30.255116]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Improve model by altering the optimiser algorithm"
      ],
      "metadata": {
        "id": "Dg0FkI_dFbHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "#compile the model and change the optimiser (Change the optimiser algorithm to adam)\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
        "              metrics =['mae'])\n",
        "#fit the model\n",
        "data =tf.expand_dims(x, axis=-1)\n",
        "model.fit(data,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-GCni7VE8Gm",
        "outputId": "a1547401-b2f2-4640-bd53-85fb34db7676"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 14.0715 - mae: 14.0715\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.8215 - mae: 11.8215\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.5715 - mae: 9.5715\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.3215 - mae: 7.3215\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.3010 - mae: 6.3010\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2492 - mae: 7.2492\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.4918 - mae: 7.4918\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0932 - mae: 7.0932\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.2575 - mae: 6.2575\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.1059 - mae: 5.1059\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1662 - mae: 4.1662\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.3156 - mae: 4.3156\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.4293 - mae: 4.4293\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2405 - mae: 4.2405\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7962 - mae: 3.7962\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.1343 - mae: 3.1343\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2857 - mae: 2.2857\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1853 - mae: 2.1853\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3386 - mae: 2.3386\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2028 - mae: 2.2028\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5849 - mae: 1.5849\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6489 - mae: 0.6489\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8198 - mae: 0.8198\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2728 - mae: 1.2728\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1947 - mae: 1.1947\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7312 - mae: 0.7312\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0079 - mae: 1.0079\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4456 - mae: 1.4456\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6127 - mae: 1.6127\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5400 - mae: 1.5400\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2544 - mae: 1.2544\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7981 - mae: 0.7981\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0408 - mae: 1.0408\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1671 - mae: 1.1671\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8546 - mae: 0.8546\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3458 - mae: 0.3458\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3831 - mae: 0.3831\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2255 - mae: 0.2255\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3936 - mae: 0.3936\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5594 - mae: 0.5594\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4569 - mae: 0.4569\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4942 - mae: 0.4942\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6206 - mae: 0.6206\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3691 - mae: 0.3691\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5182 - mae: 0.5182\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6828 - mae: 0.6828\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4473 - mae: 0.4473\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2217 - mae: 0.2217\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3476 - mae: 0.3476\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1470 - mae: 0.1470\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5978 - mae: 0.5978\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6571 - mae: 0.6571\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2845 - mae: 0.2845\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5538 - mae: 0.5538\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7932 - mae: 0.7932\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5820 - mae: 0.5820\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0741 - mae: 0.0741\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2908 - mae: 0.2908\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1032 - mae: 0.1032\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3922 - mae: 0.3922\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3638 - mae: 0.3638\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1304 - mae: 0.1304\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2604 - mae: 0.2604\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0415 - mae: 0.0415\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0377 - mae: 0.0377\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3793 - mae: 0.3793\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3223 - mae: 0.3223\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1516 - mae: 0.1516\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1474 - mae: 0.1474\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2510 - mae: 0.2510\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1850 - mae: 0.1850\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2905 - mae: 0.2905\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2988 - mae: 0.2988\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1036 - mae: 0.1036\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0521 - mae: 0.0521\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3830 - mae: 0.3830\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3546 - mae: 0.3546\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0827 - mae: 0.0827\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0667 - mae: 0.0667\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3506 - mae: 0.3506\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3151 - mae: 0.3151\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1232 - mae: 0.1232\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1113 - mae: 0.1113\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3034 - mae: 0.3034\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2743 - mae: 0.2743\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1464 - mae: 0.1464\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1220 - mae: 0.1220\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2994 - mae: 0.2994\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2791 - mae: 0.2791\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1418 - mae: 0.1418\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1254 - mae: 0.1254\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2755 - mae: 0.2755\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2432 - mae: 0.2432\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1797 - mae: 0.1797\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1617 - mae: 0.1617\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2550 - mae: 0.2550\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2353 - mae: 0.2353\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1637 - mae: 0.1637\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1355 - mae: 0.1355\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2833 - mae: 0.2833\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc2e44a58b0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#See if model prediction has improved\n",
        "model.predict([17.0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3roz4TAuIWga",
        "outputId": "921ec0a3-04ee-4e03-a164-f73512f7292b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc2e4574dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 59ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[27.677097]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    }
  ]
}